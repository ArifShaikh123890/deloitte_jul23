from pyspark.sql import SparkSession
from pyspark.sql.functions import split, explode

if __name__ == '__main__':
    spark = SparkSession.builder \
        .appName('Read Write S3') \
        .master('local[*]') \
        .config('spark.jars.packages', 'org.apache.hadoop:hadoop-aws:3.2.0') \
        .config('fs.s3a.access.key', '') \
        .config('fs.s3a.secret.key', '') \
        .config('fs.s3a.endpoint', 's3.amazonaws.com') \
        .getOrCreate()

    moviesDf = spark.read.format('csv') \
        .option('header', 'true') \
        .option('inferSchema', 'true') \
        .load('s3a://arif-bkt-deloct23/input/movies.csv')
    # moviesDf.show(5, truncate=False)

    splitDf = moviesDf\
        .select('movieId', 'title', explode(split('genres', '\|')).alias('genres'))

    splitDf.write.mode('overwrite').format('csv') \
        .save('s3a://arif-bkt-deloct23/output/movies_op')
    print('*****Data Written to HDFS Successfully****')
